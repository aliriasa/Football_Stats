{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWUs-T2r6YHw"
      },
      "source": [
        "### DATA SCRAPING OF TRANSFERMARKET AND FBREF FOR SPORTS ANALYTICS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvjq6dXx6YHy"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "neSscqqn6YHy"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz7GZzrN6YHz"
      },
      "source": [
        "Obtain Transfermarkt and FBref Websites for Scraping (Manually Selected Websites) - Automate the Process in the Future"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EloxZMsS6YHz"
      },
      "outputs": [],
      "source": [
        "excel_file = 'transfer_links.xlsx'\n",
        "\n",
        "urls = pd.read_excel(excel_file, header=None, names=['Transfermarkt', 'Fbref', 'League'])\n",
        "urls_transfermarkt = urls['Transfermarkt'].to_numpy()\n",
        "urls_fbref = urls['Fbref'].to_numpy()\n",
        "leagues = urls['League'].to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8y5icJb6YHz"
      },
      "source": [
        "Define Function to Get HTML Code from a Website"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M2hNcJl26YHz"
      },
      "outputs": [],
      "source": [
        "def get_Soup(page):\n",
        "    headers = {'User-Agent':\n",
        "                 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}\n",
        "    pageTree = requests.get(page, headers=headers)\n",
        "    pageSoup = BeautifulSoup(pageTree.content, 'html.parser')\n",
        "    return pageSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BtOd8YT6YHz"
      },
      "source": [
        "Define Function to Get Table HTML Code from Transfermarkt Website"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DRzN7REm6YHz"
      },
      "outputs": [],
      "source": [
        "def get_information (pageSoup):\n",
        "\n",
        "    rows_bi = pageSoup.find_all(\"td\", {\"class\": \"posrela\"})\n",
        "    rows_ai = pageSoup.find_all(\"td\", {\"class\": \"zentriert\"})\n",
        "    rows_mi = pageSoup.find_all(\"td\", {\"class\": \"rechts hauptlink\"})\n",
        "\n",
        "    grouped_rows = []\n",
        "    for i in range(0, len(rows_ai), 8):\n",
        "        group = rows_ai[i:i+8]\n",
        "        grouped_rows.append(group)\n",
        "\n",
        "    return rows_bi, grouped_rows, rows_mi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjmJ3EAy6YHz"
      },
      "source": [
        "Define Function to Get Transfermarkt Player Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zkJpdyke6YHz"
      },
      "outputs": [],
      "source": [
        "def get_players_information (league, team, rows_bi, grouped_rows, rows_mi):\n",
        "\n",
        "    players = []\n",
        "\n",
        "    for row in rows_bi:\n",
        "        dict = {}\n",
        "\n",
        "        dict[\"Liga\"] = league\n",
        "\n",
        "        dict['Equipo'] = team\n",
        "\n",
        "        # Extract player name\n",
        "        dict[\"Nombre\"] = row.find_all('td')[1].text.strip()\n",
        "\n",
        "        # Extract image\n",
        "        dict[\"Imagen\"] = row.find('img', {'data-src': True})['data-src']\n",
        "\n",
        "        # Extract position\n",
        "        dict[\"Posicion\"] = row.find_all('td')[2].text.strip()\n",
        "\n",
        "\n",
        "        try:\n",
        "            dict['Lesionado'] = row.find_all('td')[1].find('span').get('title')\n",
        "        except:\n",
        "            dict['Lesionado'] = np.nan\n",
        "\n",
        "        try:\n",
        "            dict['Estado jugador'] = row.find('a', class_='hide-for-small').get('title')\n",
        "        except:\n",
        "            dict['Estado jugador'] = np.nan\n",
        "\n",
        "        players.append(dict)\n",
        "\n",
        "    index = 0\n",
        "    for row in grouped_rows:\n",
        "\n",
        "        dict = players[index]\n",
        "\n",
        "        # Extract player number\n",
        "        try:\n",
        "            dict[\"Numero\"] = row[0].text\n",
        "        except:\n",
        "            dict[\"Numero\"] = np.nan\n",
        "\n",
        "        # Extract dob\n",
        "        try:\n",
        "            dict[\"Fecha de Nacimiento\"] = row[1].text[:10]\n",
        "        except:\n",
        "            dict[\"Fecha de Nacimiento\"] = np.nan\n",
        "\n",
        "        # Extract age\n",
        "        try:\n",
        "            dict[\"Edad\"] = row[1].text[12:14]\n",
        "        except:\n",
        "            dict[\"Edad\"] = np.nan\n",
        "\n",
        "\n",
        "        # Extract nationality (JUST THE FIRST ONE)\n",
        "        try:\n",
        "            dict[\"Nacionalidad\"] = row[2].img['alt']\n",
        "        except:\n",
        "            dict[\"Nacionalidad\"] = np.nan\n",
        "\n",
        "        # Extract altura\n",
        "        try:\n",
        "            dict[\"Altura\"] = row[3].text\n",
        "        except:\n",
        "            dict[\"Altura\"] = np.nan\n",
        "\n",
        "        # Extract pie\n",
        "        try:\n",
        "            dict[\"Pie\"] = row[4].text\n",
        "        except:\n",
        "            dict[\"Pie\"] = np.nan\n",
        "\n",
        "        # Extract fichado\n",
        "        try:\n",
        "            dict[\"Fecha de incorporacion\"] = row[5].text\n",
        "        except:\n",
        "            dict[\"Fecha de incorporacion\"] = np.nan\n",
        "\n",
        "        # Extract anterior equipo\n",
        "        try:\n",
        "            dict[\"Anterior Equipo\"] = row[6].img['alt']\n",
        "        except:\n",
        "            dict[\"Anterior Equipo\"] = np.nan\n",
        "\n",
        "        # Extract contrato\n",
        "        try:\n",
        "            dict[\"Fecha de fin de contrato\"] = row[7].text\n",
        "        except:\n",
        "            dict[\"Fecha de fin de contrato\"] = np.nan\n",
        "\n",
        "        index += 1\n",
        "\n",
        "    index = 0\n",
        "    for row in rows_mi:\n",
        "        dict = players[index]\n",
        "\n",
        "        # Extract valor de mercado\n",
        "        dict[\"Valor de mercado\"] = row.text\n",
        "\n",
        "        index += 1\n",
        "\n",
        "    return players"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGCyd-S46YH0"
      },
      "source": [
        "Get Player Information from All Transfermarkt Websites (7 min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y1eQRNtI6YH0"
      },
      "outputs": [],
      "source": [
        "all_players = np.array([])\n",
        "index = 0\n",
        "\n",
        "for page in urls_transfermarkt:\n",
        "    try:\n",
        "        pageSoup = get_Soup(page)\n",
        "        league = leagues[index]\n",
        "        team = urls_fbref[index].split('/')[-1].replace('-', ' ').replace(' Stats', '')\n",
        "        rows_bi, grouped_rows, rows_mi = get_information(pageSoup)\n",
        "        players = get_players_information(league, team, rows_bi, grouped_rows, rows_mi)\n",
        "        all_players = np.concatenate((all_players, players))\n",
        "    except Exception as e:\n",
        "        print(page)\n",
        "        print(e)\n",
        "    index += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95jJNsKN6YH0"
      },
      "source": [
        "Define Functions to transform DataFrame columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Q5FjryR-6YH0"
      },
      "outputs": [],
      "source": [
        "def n_int(n_str):\n",
        "    try:\n",
        "        return int(n_str)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "def altura_to_m(string):\n",
        "    try:\n",
        "        return int(string[0] + string[2:4])/100\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "def value_to_int(value):\n",
        "    try:\n",
        "        cleaned_value = value.replace(',', '').replace(' mill. €', '')\n",
        "        converted_value = int(cleaned_value)/100\n",
        "        return converted_value\n",
        "    except:\n",
        "        try:\n",
        "            cleaned_value = value.replace(',', '').replace(' mil €', '')\n",
        "            converted_value = int(cleaned_value)/1000\n",
        "            return converted_value\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "def convert_to_date(date_string):\n",
        "    try:\n",
        "        date_format = \"%d/%m/%Y\"\n",
        "        converted_date = datetime.strptime(date_string.strip(), date_format).date()\n",
        "        return converted_date\n",
        "    except:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6xVNF6A6YH0"
      },
      "source": [
        "Transfermarkt DataFrame (Clean certain Transfermarkt Dataframe columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bmLNEsFW6YH0"
      },
      "outputs": [],
      "source": [
        "df_transfermarkt = pd.DataFrame.from_records(all_players)\n",
        "\n",
        "df_transfermarkt['Altura'] = df_transfermarkt[\"Altura\"].apply(altura_to_m)\n",
        "df_transfermarkt[\"Valor de mercado\"] = df_transfermarkt[\"Valor de mercado\"].apply(value_to_int)\n",
        "df_transfermarkt[\"Fecha de Nacimiento\"] = df_transfermarkt[\"Fecha de Nacimiento\"].apply(convert_to_date)\n",
        "df_transfermarkt[\"Fecha de incorporacion\"] = df_transfermarkt[\"Fecha de incorporacion\"].apply(convert_to_date)\n",
        "df_transfermarkt[\"Fecha de fin de contrato\"] = df_transfermarkt[\"Fecha de fin de contrato\"].apply(convert_to_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y3ZZZ9O6YH0"
      },
      "source": [
        "Define Function to Get Player Information from FBref Website"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xHDe65C16YH1"
      },
      "outputs": [],
      "source": [
        "def get_players_statistics(page, pageSoup):\n",
        "    data_dict = {}\n",
        "\n",
        "    sections = {\n",
        "        'gk_info': 'all_stats_keeper_adv',\n",
        "        'shooting_info': 'all_stats_shooting',\n",
        "        'passing_info': 'all_stats_passing',\n",
        "        'pass_type_info': 'all_stats_passing_types',\n",
        "        'gca_info': 'all_stats_gca',\n",
        "        'defense_info': 'all_stats_defense',\n",
        "        'possession_info': 'all_stats_possession',\n",
        "        'playing_time_info': 'all_stats_playing_time',\n",
        "        'misc_info': 'all_stats_misc'\n",
        "    }\n",
        "\n",
        "\n",
        "    dict_all = {}\n",
        "    club_name = page.split('/')[-1].replace('-', ' ').replace(' Stats', '')\n",
        "    for key, value in sections.items():\n",
        "        try:\n",
        "            section_info = pageSoup.find('div', id=value)\n",
        "            section_col = np.unique([td['data-stat'] for td in section_info.find_all('td')])\n",
        "            table = section_info.find('tbody')\n",
        "            rows = table.find_all('tr')\n",
        "            for row in rows:\n",
        "                data_dict = {}\n",
        "                try:\n",
        "                    player = row.find('th', attrs={'data-stat': 'player'}).text\n",
        "                    data_dict['player'] = player if player else np.nan\n",
        "                    data_dict['team'] = club_name\n",
        "                except:\n",
        "                    data_dict['player'] = np.nan\n",
        "                    data_dict['team'] = np.nan\n",
        "\n",
        "                for stat in section_col:\n",
        "                    try:\n",
        "                        value = row.find('td', attrs={'data-stat': stat}).text\n",
        "                        data_dict[stat] = value if value else np.nan\n",
        "                    except:\n",
        "                        data_dict[stat] = np.nan\n",
        "\n",
        "                if data_dict['player'] in list(dict_all.keys()):\n",
        "                    dict_all[data_dict['player']].update(data_dict)\n",
        "                else:\n",
        "                    dict_all[data_dict['player']] = data_dict\n",
        "        except:\n",
        "            print((page, value))\n",
        "\n",
        "    return dict_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRiNcVJK6YH1"
      },
      "source": [
        "Fbref DataFrame (3 hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tGDBJ9d6YH1",
        "outputId": "c2cf59c0-cca6-4e7d-baa7-3163ddec013c"
      },
      "outputs": [],
      "source": [
        "overall_df = pd.DataFrame()\n",
        "\n",
        "for page in urls_fbref:\n",
        "    try:\n",
        "        pageSoup = get_Soup(page)\n",
        "        dict_all = get_players_statistics(page, pageSoup)\n",
        "        player_list = []\n",
        "        for player, info in dict_all.items():\n",
        "            player_info = {'Player': player}\n",
        "            player_info.update(info)\n",
        "            player_list.append(player_info)\n",
        "        df_fbref = pd.DataFrame(player_list)\n",
        "        overall_df = pd.concat([overall_df, df_fbref], ignore_index=True)  # Concatenate the current dataframe with the overall dataframe\n",
        "        overall_df.to_csv('fbref_stats.csv')\n",
        "\n",
        "        time.sleep(1)\n",
        "    except:\n",
        "        print(page)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcoP8Sj96YH1"
      },
      "source": [
        "Read Saved Fbref DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gulOPbIi6YH1"
      },
      "outputs": [],
      "source": [
        "df_fbref = pd.read_csv('fbref_stats.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-4fIE8r6YH2"
      },
      "source": [
        "Merge Transfermarkt & Fbref DataFrames by player name and team"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "esTTMv8W6YH2"
      },
      "outputs": [],
      "source": [
        "stats_df = pd.merge(df_transfermarkt, df_fbref, left_on=['Nombre', 'Equipo'], right_on=['player', 'team'], how='inner')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlRiXn_h6YH2"
      },
      "source": [
        "Save merged DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DH_gNC496YH2"
      },
      "outputs": [],
      "source": [
        "stats_df.to_csv('transfer.csv', index = False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
